---
output: reprex::reprex_document
knit: reprex::reprex_render
---

# Packages

Let's first load in the packages needed for this task using the `library()` function.

```{r}
library(tidyverse)
library(visdat)
library(lme4)
library(lmerTest)
library(emmeans)
library(buildmer)
library(performance)
```

We then read in our dataset using the `read_csv()` function.

```{r}
raw_data <- read_csv("raw_data.csv")
```

We can use the `vis_miss()` function from the library `visdat` to identify any areas which are missing data.

```{r}
vis_miss(raw_data)
```

`vis_miss()` creates a visualisation of all the missing data in our dataset and shows us where the data are missing. It appears as though all the values below 150 are missing. This is not surprising, considering that we were given a sample dataset of 500. We can also see that there are columnms which contain only `NA` values. The code below creates a new dataset containing only the first 500 rows, as well as the columns which contain at least 1 non-NA observation.

```{r}
data <- head(raw_data, 500) # We select only the first 500 rows
data <- data %>%
    mutate(TRANS_DATE = MONTH) %>%
    select(!MONTH)
data <- data[, colSums(is.na(data)) < nrow(data)] # We remove columns which are all NA
data$LOYALTY <- toupper(data$LOYALTY) # We made all the labels for LOYALTY upper case
data <- data %>%
    mutate(LOYALTY = factor(LOYALTY)) # We factorise LOYALTY

# We run an if statement to see if CUST_AREA and CUST_REGION are identical. If so, we remove CUST_AREA
if (all(sapply(list(data$CUST_AREA, data$CUST_REGION), FUN = identical, data$REGION)) == TRUE) {
    data <- data %>%
        select(!CUST_AREA & !CUST_REGION)
}
```

Let's have another look at the missing data using `vis_miss()`

```{r}
vis_miss(data)
```

This is better - the appropriate NA data have been removed. We can view the first 10 observations using the `head()` function

```{r}
head(data, 10)
```

Interestingly, it appears as though `CUST_REGION` and `CUST_AREA` may be identical. We can use the `identical` function to asseess this claim.

We can see that they are, in fact, identical. Let's remove the `CUST_AREA` column from the dataset

# Loyalty

## Summary Statistics

Let's create some summary stats of `LOYALTY`.

```{r}
(loy_sum <- data %>%
    group_by(LOYALTY) %>%
    summarise(mean_value = mean(VALUE), sd_value = sd(VALUE)) %>%
    arrange(-mean_value))
```

## Visualisations

```{r}
loy_sum %>%
    ggplot(aes(x = LOYALTY, y = mean_value, fill = LOYALTY)) +
    geom_col() +
    theme_minimal() +
    guides(fill = "none") +
    labs(x = "Loyalty Scheme",
        y = "Mean Value",
        title = "The Effect of Customer Loyalty on Mean Value") +
        theme(text = element_text(size = 25),
                plot.title = element_text(size = 30,
                hjust = 0.5, margin = margin(b = 20)))
```

## Linear Model

Let's build a linear model to assess whether `LOYALTY` had a significant effect on `TOTAL_COST`

```{r}
loyal_model <- buildmer(VALUE ~ LOYALTY +
    (1 + LOYALTY | LOYALTY_ID) +
    (1 + LOYALTY | TRANS_ID) +
    (1 + LOYALTY | NO_OF_ITEMS) +
    (1 + LOYALTY | ITEM_VOL) +
    (1 + LOYALTY | LOYALTY_ID) +
    (1 + LOYALTY | DELIVERY_METHOD) +
    (1 + LOYALTY | DELIVERY_COST) +
    (1 + LOYALTY | ITEM_VOLUME),
    buildmerControl = buildmerControl(direction = "order"),
    data = data)
summary(loyal_model)
```

It appears as though `LOYALTY` did not have a significant effect on `VALUE` of item (*p* = .191)

# Region

## National Promotion

Let's have a look at some summary stats for `REGION`. Let's first have a look at the April and May promotion

```{r}
(Nat_pro_sum <- data %>%
    group_by(TRANS_DATE) %>%
    summarise(mean_value = mean(VALUE), sd_value = sd(VALUE)) %>%
    arrange(-mean_value))
```

```{r}
Nat_pro_sum %>%
    mutate(TRANS_DATE = fct_relevel(TRANS_DATE,
            "Jan-19", "Feb-19", "Mar-19",
            "Apr-19", "May-19", "Jun-19",
            "Jul-19", "Aug-19", "Sep-19",
            "Oct-19", "Nov-19", "Dec-19")) %>%
    ggplot(aes(x = TRANS_DATE, y = mean_value,
            fill = factor(ifelse(TRANS_DATE == "Apr-19" | TRANS_DATE == "May-19",
            "Highlighted", "Normal")))) +
    geom_col() +
    geom_text(aes(x = "May-19",
                  y = 58),
                  label = "National\nSpring Clean\nPromotion",
                  angle = 40,
                  size = 9,
                  position = position_nudge(x = -0.45)) +
    guides(fill = "none") +
    theme_minimal() +
    labs(x = "Transaction Date",
        y = "Mean Transaction Value",
        title = "Mean Transaction Value\nOver the Previous Year") +
    theme(text = element_text(size = 30),
        plot.title = element_text(size = 35,
          hjust = 0.5, margin(b = 25), face = "bold"),
        axis.text.x = element_text(angle = 45))

```

### Building our model

```{r}
ordered_data <- data %>%
    mutate(TRANS_DATE = fct_relevel(TRANS_DATE,
            "Jan-19", "Feb-19", "Mar-19",
            "Apr-19", "May-19", "Jun-19",
            "Jul-19", "Aug-19", "Sep-19",
            "Oct-19", "Nov-19", "Dec-19"))
date_model <- lm(VALUE ~ TRANS_DATE,
    data = ordered_data)
summary(date_model)
```

It looks as though the promotions run in `Apr-19` and `May-19` did not have a signficiant impact on `VALUE`. 

## GL and WM Promotion

```{r}
gl_wm_data <- data %>%
filter(REGION == "GL" | REGION == "WM") %>%
mutate(TRANS_DATE = fct_relevel(TRANS_DATE,
            "Jan-19", "Mar-19",
            "Apr-19", "May-19", "Jun-19",
            "Jul-19", "Aug-19", "Sep-19",
            "Oct-19", "Nov-19", "Dec-19"))
```

## Summary Stats

Let's now generate some summary statistics 

```{r}
(reg_sum <- gl_wm_data %>%
    group_by(TRANS_DATE) %>%
    summarise(mean_value = mean(VALUE), sd_value = sd(VALUE)) %>%
    arrange(-mean_value))
```

```{r}
reg_sum %>%
    mutate(TRANS_DATE = fct_relevel(TRANS_DATE,
            "Jan-19", "Mar-19", "Apr-19",
            "May-19", "Jun-19", "Jul-19",
            "Aug-19", "Sep-19", "Oct-19",
            "Nov-19", "Dec-19")) %>%
    ggplot(aes(x = TRANS_DATE, y = mean_value,
    fill = factor(ifelse(TRANS_DATE == "Aug-19", "Highlighted", "Normal")))) +
    geom_col() +
    guides(fill = "none") +
    theme_minimal() +
    labs(x = "Transaction Date",
        y = "Mean Transaction Value",
        title = "Mean Amount of Money Spent in GL and WM\nOver the Previous Year") +
    theme(text = element_text(size = 30),
        plot.title = element_text(size = 30,
        hjust = 0.5, margin = margin(b = 20), face = "bold"),
        axis.text.x = element_text(angle = 45))
```

## Building our Model

```{r}
gl_wm_model <- lmer(VALUE ~ TRANS_DATE +
                   (1 + TRANS_DATA | ITEM_COST),
                   data = gl_wm_data)
summary(gl_wm_model)
```

Our next model assesses whether `REGION` had a significant effect on VALUE


This final model examines any interactions between LOYALTY and REGION on VALUE. 

```{r}
mixed_model <- buildmer(VALUE ~ LOYALTY * REGION +
    (1 + LOYALTY * REGION | LOYALTY_ID) +
    (1 + LOYALTY * REGION | TRANS_ID) +
    (1 + LOYALTY * REGION | NO_OF_ITEMS) +
    (1 + LOYALTY * REGION | ITEM_VOL) +
    (1 + LOYALTY * REGION | LOYALTY_ID) +
    (1 + LOYALTY * REGION | DELIVERY_METHOD) +
    (1 + LOYALTY * REGION | DELIVERY_COST) +
    (1 + LOYALTY * REGION | ITEM_VOLUME),
    buildmerControl = buildmerControl(direction = "order"),
    data = data)
summary(mixed_model)
```